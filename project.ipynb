{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files\n",
    "This cell is culled from Udacity provided template for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ernest/Documents/data engineering /apache_cassandra_data_modeling\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# checking the current working directory \n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    print(len(file_path_list)) # get the total number of files in the path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables\n",
    "Culled from the Udacity provided template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in the csv file. Provided by Udacity\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra codes in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance in the local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, we need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS ernest \\\n",
    "                    WITH REPLICATION = \\\n",
    "                    {'class': 'SimpleStrategy', 'replication_factor': 1}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('ernest')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following tables are created for specific queries in mind. This is because in Apache Cassandra, the database tables are modeled based on the expected queries. The queries are presented below. The test.ipynb also shows the specific queries of each table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a song_library table\n",
    "#### PARTITION KEY is sessionId. This implies that data is distributed using the sessionId\n",
    "#### CLUSTERING COLUMN is made up of the itemInsession to ensure unique PRIMARY KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"drop table IF EXISTS song_library\")\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_library\"\n",
    "query = query + \"(sessionId INT, \\\n",
    "                  itemInSession INT,\\\n",
    "                  artist TEXT, \\\n",
    "                  song TEXT, \\\n",
    "                  length DOUBLE, \\\n",
    "                  PRIMARY KEY(sessionId, itemInsession))\"             \n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print('Error Creating table', e)\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "\n",
    "        query = \"INSERT INTO song_library(SessionId, itemInSession, artist, song, length )\"\n",
    "        query = query + \"VALUES(%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artist_library table\n",
    "#### PARTITION KEY is made up of userId and sessionId, that means data is distributed using userId and sessionId.\n",
    "#### CLUSTERING COLUMN consists of itemInSession\n",
    "##### songs are sorted by itemInSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"drop table IF EXISTS artist_library\")\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_library\"\n",
    "query = query + \"(userId INT, \\\n",
    "                 sessionId INT, \\\n",
    "                 itemInSession INT,\\\n",
    "                 artist TEXT, \\\n",
    "                 first TEXT, \\\n",
    "                 last TEXT,\\\n",
    "                 song TEXT,  \\\n",
    "                 PRIMARY KEY((userId, sessionId), itemInSession))\"             \n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print('Error Creating table\\n', e)\n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "\n",
    "        query = \"INSERT INTO artist_library( userId, SessionId, itemInSession, artist, first, last, song )\"\n",
    "        query = query + \"VALUES(%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]) , line[0], line[1], line[4],  line[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create user table \n",
    "#### PARTITION KEY is song. That means data is distributed  across  the nodes using song\n",
    "#### CLUSTERING COLUMN is userId to keep the PRIMARY KEY UNIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.execute(\"drop table IF EXISTS user\")\n",
    "query = \"CREATE TABLE IF NOT EXISTS user\"\n",
    "query = query + \"(song TEXT, \\\n",
    "                 userId INT, \\\n",
    "                 artist TEXT,\\\n",
    "                 first TEXT, last TEXT, \\\n",
    "                 PRIMARY KEY(song, userId))\"             \n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print('Error Creating table\\n', e)\n",
    "\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "\n",
    "        query = \"INSERT INTO user( song, userId, artist, first, last )\"\n",
    "        query = query + \"VALUES( %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        session.execute(query, (line[9], int(line[10]), line[0], line[1], line[4]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data modeling is verified using the following queries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Query 1:  Get the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist is 'Faithless'. The song is 'Music Matters (Mark Knight Dub)'. And the length is '495.3073'\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song, length FROM song_library WHERE sessionId = 338 and itemInSession = 4  \"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    for row in rows:\n",
    "        print( \"The artist is '{}'. The song is '{}'. And the length is '{}'\".format( row.artist, row.song, row.length))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The artist is <font color=green > Faithless </font>\n",
    "#### The song is <font color=green >  Music Matters (Mark Knight Dub) </font>\n",
    "#### And the length is <font color=green >  495.3073 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: Get only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist is 'Down To The Bone'.\n",
      " The title of the song is 'Keep On Keepin' On'.\n",
      " The user is 'Sylvie Cruz'\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song, first, last FROM artist_library WHERE userId = 10 and itemInSession = 0 and sessionId = 182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "    for row in rows:\n",
    "        print(\"The artist is '{}'.\\n The title of the song is '{}'.\\n The user is '{} {}'\".format(row[0], row[1], row[2], row[3]))\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The artist is <font color=green >\"Down To The Bone\"</font>\n",
    "#### The title of the song is <font color=green >\"Keep On Keepin' On \"</font>\n",
    "#### The user is <font color=green >\"Sylvie Cruz\"</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Query 3: Get every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following user(s) listened to the song, 'All Hands Against His Own':\n",
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT first, last FROM user WHERE song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    song = 'All Hands Against His Own'\n",
    "    rows = session.execute(query)\n",
    "    print(\"The following user(s) listened to the song, '{}':\".format(song))\n",
    "    for row in rows:\n",
    "        print(row.first, row.last)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color= blue> The following user(s) listened to the song,</font>  <font color= red> 'All Hands Against His Own'</font> :\n",
    "#### <font color= green>  Jacqueline Lynch</font> \n",
    "#### <font color= green> Tegan Levine</font> \n",
    "#### <font color= green> Sara Johnson</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_song_library = \"DROP TABLE IF EXISTS song_library\"\n",
    "drop_artist_library = \"DROP TABLE IF EXISTS artist_library\"\n",
    "drop_user = \"DROP TABLE IF EXISTS user\"\n",
    "tables = [drop_song_library, drop_artist_library, drop_user]\n",
    "\n",
    "for t in tables:\n",
    "    session.execute(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
